### Reddit community points Smart Contracts POC

Repository accompanying the rollup diff compression research, using the Reddit's airdrop as a usecase.

You can read more about the research [here](https://medium.com/privacy-scaling-explorations/rollup-diff-compression-application-level-compression-strategies-to-reduce-the-l2-data-footprint-d14291acc825).

Datasets used in this experiment:

- `bricks` (`r/FortNiteBR`),
- `moons` (`r/CryptoCurrencies`).

This repository contains the smart contracts for the Reddit's airdrop. 
The smart contracts are slightly modified from the Reddit's original contracts. 
The contracts were simplified in a way that they contain what is only necessary for this PoC (e.g. GSN related stuff was removed).

Also the original contracts were using older solidity compiler version (< 0.6.0) which was limiting factor for some of the new code, 
more specifically calldata array slices were introduced in version 0.6.0, and we're heavily relying on them for the bitmap decompression part.
Increasing the compiler version caused some of the not-used old code to break, so these code chunks were also removed from the old contracts.

#### Smart contracts note

Note: The code included in this repository is based on the Reddit's original airdrop smart contracts:

```
Distributions_v0 - https://rinkeby.etherscan.io/address/0xb28e596e801c8631662c1f355213a72981c267aa#code
SubredditPoints_v0 - https://rinkeby.etherscan.io/address/0x8fdc779f1e8ae2256c663cd80e8d090c4523f159#code
Subscriptions_v0 - https://rinkeby.etherscan.io/address/0x396b89db5e9317ff25360c86bd4e2aae3bbc62ea#code
```

Furthermore, the modified contracts are not battle tested and are not production ready. 
Their purpose is to provide a Proof-of-Concept on how airdrops could be performed more efficiently
by using various application-level encoding and decoding techniques (all described in the research paper linked above).

Some of the encoding/decoding techniques in this repository are inspired from the [Arbitrum's submission](https://github.com/OffchainLabs/arb_reddit_community_points)
for the [Reddit scaling bakeoff](https://www.reddit.com/r/ethereum/comments/hbjx25/the_great_reddit_scaling_bakeoff/).

#### Install and setup instructions:
```
1. yarn install
2. cp .env.sample .env
3. Fill in the MNEMONIC variable in the .env file
```

#### Smart contracts deployment

Firstly we need to deploy the smart contracts to the appropriate network. We've tested the PoC and provided config for both local hardhat chain and local Arbitrum devnet,
which can be found in the `hardhat.config.js`. You can specify the default network by modifying the DEFAULT_NETWORK environment variable (placed in the `.env` file).
The choices for the `DEFAULT_NETWORK` variable are:
- `localhost` - for deploying on local hardhat node
- `arbitrum` - for deploying on local arbitrum node

Additionally you can specify more network configurations in the `hardhat.config.js`. 
Also note that if you're using local networks, you will need to have the networks running first. 

Deploy the smart contracts:
```
yarn deploy
```

#### Usage guide:

The repository is setup to be used by running commands from the command line. The `yargs` package is used
for parsing command line arguments and executing the appropriate scripts. The generated outputs are stored under
the `./data` directory, grouped in a separate sub-directory, determined by the action that is being executed.

The provided encoded data is placed in the `./data/encodedChunked` directory. The provided data is for test purposes only,
the full encoded data can be generated by using the [experiments repository](https://github.com/tcb0/reddit-comm-points-experiments) (both the `main` and `chunking` repository).
Additionally for the `bitmap` strategy test data was provided for faster iteration.


Here is a short description about each command:
- **Batch mint** - reads the beforehand provided encoded data and sends transactions to the deployed smart contracts. The encoded data
  contains user airdrop data, grouped and encoded to a certain strategy (this is done in the [experiments repo](https://github.com/tcb0/reddit-comm-points-experiments)). 
- **Check state** - Check the token balance of an account by `address` or `addressId`.

1. **Batch mint**:
   - `node scripts/batchMint.js --dataset bricks --encType bitmap --round round_1_finalized --test true` - Batch mint test data for round 1, bitmap strategy, bricks dataset
   - `node scripts/batchMint.js --dataset bricks --encType bitmap --round round_2_finalized --test true` - Batch mint test data for round 2, bitmap strategy, bricks dataset
   - `node scripts/batchMint.js --dataset bricks --encType rlp --round round_1_finalized` - Batch mint original data for round 1, rlp strategy, bricks dataset
   - `node scripts/batchMint.js --dataset bricks --encType rlp --round round_2_finalized` - Batch mint original data for round 2, rlp strategy, bricks dataset


2. **Check state**:
    - `node scripts/checkState.js --addrOrId 0xF88d2c407397e0C04bb026Cb9cbBD75c5685EcB8 --action addrBalance` - Check the CP token balance for address `0xF88d2c407397e0C04bb026Cb9cbBD75c5685EcB8`
    - `node scripts/checkState.js --addrOrId 1 --action idBalance` - Check the CP token balance for addressId `1`
